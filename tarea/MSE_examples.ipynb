{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos\n",
    "\n",
    "Un conjunto de $ n=50 $ observaciones y $ 25 $ parámetros. Se agrupan por tipo de error introducido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "from scipy.stats import beta;\n",
    "from scipy.stats import uniform;\n",
    "from scipy.stats import chi;\n",
    "from scipy.stats import gamma;\n",
    "from scipy.stats import lognorm;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSamples    = 50;\n",
    "numParameters = 25;\n",
    "numGroups     = 5;\n",
    "lowBound      = -5;\n",
    "highBound     = 5;\n",
    "onesVector    = np.ones(numSamples);\n",
    "lowBeta       = -15;\n",
    "highBeta      = 25;\n",
    "betaV         = np.random.randint(lowBeta, highBeta, numParameters+1)\n",
    "\n",
    "X = np.random.uniform(low=lowBound, high=highBound, size=(numSamples, numParameters))\n",
    "X = np.vstack((onesVector, X.T)).T\n",
    "\n",
    "dictResponseY = {}\n",
    "realY = X @ betaV\n",
    "#print(\"real \", realY)\n",
    "minY = np.min(realY)\n",
    "maxY = np.max(realY)\n",
    "#print(minY)\n",
    "#print(maxY)\n",
    "\n",
    "modelUniform = uniform(minY*0.0001, maxY*0.005);\n",
    "modelBeta    = beta(np.absolute(minY*0.8), np.absolute(maxY*0.8));\n",
    "modelChi     = chi(np.absolute((minY + maxY)*0.45));\n",
    "modelGamma   = gamma(np.absolute((minY + maxY)*0.05));\n",
    "modelLogNorm = lognorm(0.6);\n",
    "\n",
    "dictResponseY[\"uniforme\"]  = modelUniform.rvs(size=numSamples);\n",
    "dictResponseY[\"beta\"]      = modelBeta.rvs(size=numSamples);\n",
    "dictResponseY[\"chi\"]       = modelChi.rvs(size=numSamples);\n",
    "dictResponseY[\"gamma\"]     = modelGamma.rvs(size=numSamples);\n",
    "dictResponseY[\"logNormal\"] = modelLogNorm.rvs(size=numSamples);\n",
    "\n",
    "#print(\"dictResponseY \", dictResponseY)\n",
    "\n",
    "dictResponseY[\"uniforme\"]  += realY;\n",
    "dictResponseY[\"beta\"]      += realY;\n",
    "dictResponseY[\"chi\"]       += realY;\n",
    "dictResponseY[\"gamma\"]     += realY;\n",
    "dictResponseY[\"logNormal\"] += realY;\n",
    "\n",
    "#print(\"dictResponseY sum \", dictResponseY)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal múltiple\n",
    "\n",
    "$$ y_i = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p + \\epsilon $$\n",
    "\n",
    "##### El modelo\n",
    "\n",
    "$$ \\bf{\\hat{Y}} = \\begin{bmatrix} 1 & x_{1,1} & \\cdots & x_{1,p} \\\\ 1 & x_{2,1} & \\cdots & x_{2,p}  \\\\ \\vdots & \\vdots& \\ddots &\\vdots \\\\ 1 & x_{n,1} & \\cdots & x_{n,p}   \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_n \\end{bmatrix} = \\begin{bmatrix} \\hat{y_1} \\\\ \\hat{y_2} \\\\ \\vdots \\\\ \\hat{y_n} \\end{bmatrix} = \\bf{X} \\bf{\\beta}$$\n",
    "\n",
    "$$ \\bf{\\hat{\\beta}} = (\\bf{X}^T \\bf{X})^{-1}\\bf{X}^T\\bf{y}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterio de mínimos cuadrados\n",
    "\n",
    "Forma de medir la cercanía de la la línea con el conjunto de datos.\n",
    "\n",
    "#### El residual\n",
    "\n",
    "$$ e_i = y_i - \\hat{y_i} $$\n",
    "\n",
    "- $ y_i $ valor de $ i $-ésima respuesta observada $ \\hat{y}_i $ es el valor de la respuesta $ i $-ésima predicha por el modelo.\n",
    "\n",
    "#### Suma residual de cuadrados (RSS)\n",
    "\n",
    "$$ RSS = e_1^2 + e_2^2 + \\cdots + e_n^2 $$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de optimización\n",
    "\n",
    "**El obejtivo es estimar los parámetros $ \\hat{\\beta_0} $ y $ \\hat{\\beta_1} $ para minimizar el RSS**\n",
    "\n",
    "$$ \\bf{e(\\bf{\\beta})} = \\frac{1}{2}(\\bf{y} - \\bf{X} \\bf{\\beta})^T (\\bf{y} - \\bf{X} \\bf{\\beta}) $$\n",
    "\n",
    "$$ \\bf{\\hat{\\beta}} = \\bf{\\beta^*} = arg\\ \\underset{\\bf{\\beta}}{min} \\ \\bf{e(\\beta)} = arg\\ \\underset{\\bf{\\beta}}{min} \\frac{1}{2}(\\bf{y} - \\bf{X} \\bf{\\beta})^T (\\bf{y} - \\bf{X} \\bf{\\beta}) $$\n",
    "\n",
    "Se encuentra el mínimo a través de la derivada.\n",
    "\n",
    "$$ \\frac{d \\bf{e(\\bf{\\beta})}}{d\\bf{\\beta}} = 0 $$\n",
    "\n",
    "$$ \\frac{d \\bf{e(\\bf{\\beta})}}{d\\bf{\\beta}} = \\frac{d \\bf{\\frac{1}{2} (\\bf{y}^T\\bf{y} - \\bf{y}^T\\bf{X}\\bf{\\beta} - (\\bf{X}\\bf{\\beta})^T\\bf{y} + (\\bf{X}\\bf{\\beta})^T \\bf{X}\\bf{\\beta} )}}{d\\bf{\\beta}} $$\n",
    "\n",
    "$$ \\frac{d \\bf{e(\\bf{\\beta})}}{d\\bf{\\beta}} = \\frac{1}{2} (-2 \\bf{y}^T\\bf{X} + 2\\bf{X}^T \\bf{X}\\bf{\\beta} )= \\bf{0}$$\n",
    "\n",
    "$$ \\bf{\\hat{\\beta}} = (\\bf{X}^T \\bf{X})^{-1}\\bf{X}^T\\bf{y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "En el archivo \"Resultados_data.xlsx\" se guardaron los resultados.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd;\n",
    "\n",
    "nombre_resul =  'Resultados_data.xlsx';\n",
    "\n",
    "writer = pd.ExcelWriter(nombre_resul, engine='xlsxwriter')\n",
    "\n",
    "tabla_uniforme = pd.DataFrame(data=np.c_[dictResponseY[\"uniforme\"],\n",
    "                                         dictResponseY[\"beta\"],\n",
    "                                         dictResponseY[\"chi\"],\n",
    "                                         dictResponseY[\"gamma\"],\n",
    "                                         dictResponseY[\"logNormal\"]],\n",
    "                                         columns=[\"Y uniforme\", \"Y beta\",\n",
    "                                                  \"Y chi\", \"Y gamma\", \"Y logNormal\"],\n",
    "                              index=np.arange(len(dictResponseY[\"uniforme\"]))+1)\n",
    "\n",
    "tabla_X     = pd.DataFrame(X, columns=list(range(len(X[0, :]))))\n",
    "tabla_beta  = pd.DataFrame(betaV, columns=[\"beta\"], index=np.arange(len(betaV))+1)\n",
    "tabla_realY = pd.DataFrame(realY, columns=[\"Yreal\"], index=np.arange(len(realY))+1)\n",
    "\n",
    "tabla_uniforme.to_excel(writer, sheet_name='Respuestas')\n",
    "tabla_X.to_excel(writer, sheet_name='X')\n",
    "tabla_beta.to_excel(writer, sheet_name='beta')\n",
    "tabla_realY.to_excel(writer, sheet_name='Y real')\n",
    "\n",
    "writer.save()\n",
    "print(f'\\n\\nEn el archivo \"{nombre_resul}\" se guardaron los resultados.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df         = pd.read_excel(nombre_resul, sheet_name=None)\n",
    "Ydata      = df[\"Respuestas\"].to_numpy()[:, 1:]\n",
    "Xdata      = df[\"X\"].to_numpy()[:, 1:]\n",
    "Yreal      = df[\"Y real\"].to_numpy()[:, 1:]\n",
    "betaVector = df[\"beta\"].to_numpy()[:, 1:]\n",
    "#print(betaVector)\n",
    "#print(np.shape(betaVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "En el archivo \"Resultados_beta.xlsx\" se guardaron los resultados.\n"
     ]
    }
   ],
   "source": [
    "listBetaRespuesta = [];\n",
    "\n",
    "rowsY, columY = np.shape(Ydata)\n",
    "\n",
    "for Y_i in range(columY):\n",
    "    beta = np.linalg.inv(Xdata.T @ Xdata) @ Xdata.T @ Ydata[:, Y_i]\n",
    "    listBetaRespuesta.append(beta)\n",
    "    #print(\"beta \", beta)\n",
    "\n",
    "nombre_resul =  'Resultados_beta.xlsx';\n",
    "\n",
    "writer = pd.ExcelWriter(nombre_resul, engine='xlsxwriter')\n",
    "\n",
    "tabla_beta = pd.DataFrame(data=np.c_[listBetaRespuesta[0],\n",
    "                                     listBetaRespuesta[1],\n",
    "                                     listBetaRespuesta[2],\n",
    "                                     listBetaRespuesta[3],\n",
    "                                     listBetaRespuesta[4]],\n",
    "                                     columns=[\"beta uniforme\", \"beta beta\",\n",
    "                                                  \"beta chi\", \"beta gamma\", \"beta logNormal\"],\n",
    "                              index=np.arange(len(listBetaRespuesta[0]))+1)\n",
    "\n",
    "tabla_beta.to_excel(writer, sheet_name='Respuestas betas')\n",
    "\n",
    "writer.save()\n",
    "print(f'\\n\\nEn el archivo \"{nombre_resul}\" se guardaron los resultados.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [50, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6114/1834475106.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mY_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Coeficientes: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [50, 5]"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "listBetaRespuestaSklearn = [];\n",
    "\n",
    "rowsY, columY = np.shape(Ydata)\n",
    "\n",
    "for Y_i in range(columY):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(Xdata[:, 1:], Ydata[Y_i][:, np.newaxis])\n",
    "\n",
    "    print(\"Coeficientes: \\n\", regr.coef_)\n",
    "    print(\"Intercepto: \\n\", regr.intercept_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de la presición del modelo\n",
    "\n",
    "La medida en que el modelo se ajusta a los datos\n",
    "\n",
    "- $ RSE $ (Error estandar residual) Error del término $ \\epsilon $, valor estimado de la desviación estandar de $ \\epsilon $\n",
    "- $ R^2 $ estadístico.\n",
    "\n",
    "$$RSE = \\sqrt{\\frac{1}{n-2}RSS}$$\n",
    "\n",
    "- $ \\uparrow RSE $ El modelos no ajusta bien a los datos\n",
    "- $ \\downarrow RSE $ $ \\hat{y_i} \\approx  y_i $\n",
    "\n",
    "$$ R^2 = \\frac{TSS - RSS}{TSS} $$\n",
    "\n",
    "- $ TSS = \\sum (y_i - \\bar{y})^2 $ suma total de cuadrados.\n",
    "\n",
    "Proporciona una medida alternativa de ajuste del modelo (valor entre 0 y 1)\n",
    "\n",
    "- $ R^2 $ tiende a cero el modelo lineal no es el apropiado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b9f6485708e18c27c0d3bd72075ba02e2ed82c811fdd2fc15bbe4b999b91970"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
